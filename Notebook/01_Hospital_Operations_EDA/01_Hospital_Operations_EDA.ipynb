{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650d9969",
   "metadata": {},
   "source": [
    "# Hospital Operations Efficiency & Resource Utilization — EDA\n",
    "\n",
    "This notebook performs exploratory data analysis (EDA) on the hospital operations dataset. It connects to a local SQL Server, pulls the required tables, runs validation checks, and produces visualizations using **matplotlib**. The notebook is modular and intended to be run end-to-end in VS Code or Jupyter.\n",
    "\n",
    "**Author:** Aman Kumar Singh\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebf8d73",
   "metadata": {},
   "source": [
    "## 0. Requirements\n",
    "\n",
    "Install required packages in your environment before running the notebook:\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy matplotlib sqlalchemy pyodbc seaborn nbformat\n",
    "```\n",
    "\n",
    "If you plan to use SQLAlchemy + pyodbc on Windows with Windows Authentication, ensure the correct ODBC driver is installed (e.g., ODBC Driver 17 for SQL Server)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "OUTPUT_DIR = 'outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "print('Imports complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9bbf7",
   "metadata": {},
   "source": [
    "## 1. SQL Database Connection\n",
    "\n",
    "Edit the connection string below to match your environment. Uses SQLAlchemy with pyodbc driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4173831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit these values for your environment\n",
    "server = 'localhost'  # or 'localhost\\\\SQLEXPRESS'\n",
    "database = 'HospitalOpsDB'  # change to your database name\n",
    "driver = 'ODBC Driver 17 for SQL Server'\n",
    "\n",
    "# Windows Trusted Connection example\n",
    "connection_url = f\"mssql+pyodbc://@{server}/{database}?driver={driver.replace(' ', '+')}&trusted_connection=yes\"\n",
    "\n",
    "print('Connection URL (sanitized):', connection_url)\n",
    "\n",
    "try:\n",
    "    engine = create_engine(connection_url)\n",
    "    print('✅ SQLAlchemy engine created')\n",
    "except Exception as e:\n",
    "    print('❌ Could not create engine — check connection details')\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d2447a",
   "metadata": {},
   "source": [
    "## 2. Load core tables into pandas\n",
    "We'll load the 8 core tables into DataFrames. If the table names differ, update the SQL accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = ['Hospitals','Departments','Staff','Patients','Admissions','Surgeries','ResourceUtilizationSnapshots','Financials']\n",
    "\n",
    "df = {}\n",
    "for t in table_names:\n",
    "    try:\n",
    "        df[t] = pd.read_sql_table(t, con=engine)\n",
    "        print(f\"Loaded {t}:\", df[t].shape)\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            df[t] = pd.read_sql(f'SELECT * FROM {t}', con=engine)\n",
    "            print(f\"Loaded {t} via read_sql:\", df[t].shape)\n",
    "        except Exception as ex:\n",
    "            print(f\"Failed to load {t}:\", ex)\n",
    "\n",
    "for k in df:\n",
    "    display(k, df[k].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adaa607",
   "metadata": {},
   "source": [
    "## 3. Basic Validation & Integrity Checks\n",
    "Run quick sanity checks similar to what we ran in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Row counts\n",
    "for t in table_names:\n",
    "    if t in df:\n",
    "        print(f\"{t}: {len(df[t])}\")\n",
    "\n",
    "# 3.2 Null foreign keys and referential checks\n",
    "print('\\nReferential checks:')\n",
    "if 'Departments' in df and 'Hospitals' in df:\n",
    "    orphans = df['Departments'][~df['Departments']['HospitalID'].isin(df['Hospitals']['HospitalID'])]\n",
    "    print('Orphan Departments:', len(orphans))\n",
    "\n",
    "if 'Staff' in df and 'Departments' in df:\n",
    "    orphans = df['Staff'][~df['Staff']['DeptID'].isin(df['Departments']['DeptID'])]\n",
    "    print('Orphan Staff rows:', len(orphans))\n",
    "\n",
    "# 3.3 Date logic\n",
    "if 'Admissions' in df:\n",
    "    bad_dates = df['Admissions'][pd.to_datetime(df['Admissions']['DischargeDate']) < pd.to_datetime(df['Admissions']['AdmissionDate'])]\n",
    "    print('Admissions with discharge < admit:', len(bad_dates))\n",
    "\n",
    "# 3.4 Range checks for utilization\n",
    "if 'ResourceUtilizationSnapshots' in df:\n",
    "    r = df['ResourceUtilizationSnapshots']\n",
    "    print('BedOcc min/max:', r['BedOccupancyRate'].min(), r['BedOccupancyRate'].max())\n",
    "    print('EquipUtil min/max:', r['EquipmentUtilizationRate'].min(), r['EquipmentUtilizationRate'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f78b58",
   "metadata": {},
   "source": [
    "## 4. Descriptive Statistics\n",
    "Overview statistics for key tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55dd7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Admissions' in df:\n",
    "    print('Admissions summary:')\n",
    "    display(df['Admissions'].describe(include='all'))\n",
    "\n",
    "if 'Patients' in df:\n",
    "    print('Patients age distribution:')\n",
    "    display(df['Patients']['Age'].describe())\n",
    "\n",
    "if 'Staff' in df:\n",
    "    print('Staff by Role:')\n",
    "    display(df['Staff'].groupby('Role').agg({'StaffID':'count','ExperienceYears':'mean','Salary':'mean'}).reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3cce5",
   "metadata": {},
   "source": [
    "## 5. Operational Analysis\n",
    "Visualizing key operational metrics: LOS distribution, Bed occupancy, Readmission rate, ER wait times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c00f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "if 'Admissions' in df:\n",
    "    los = df['Admissions']['LengthOfStay'].dropna()\n",
    "    plt.hist(los, bins=range(0,31), alpha=0.8)\n",
    "    plt.title('Length of Stay Distribution')\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'los_hist.png'))\n",
    "    plt.show()\n",
    "\n",
    "# Bed occupancy histogram\n",
    "if 'ResourceUtilizationSnapshots' in df:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(df['ResourceUtilizationSnapshots']['BedOccupancyRate'].dropna()*100, bins=30)\n",
    "    plt.title('Bed Occupancy Rate (%) Distribution')\n",
    "    plt.xlabel('Occupancy %')\n",
    "    plt.ylabel('Snapshots')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'bed_occupancy_hist.png'))\n",
    "    plt.show()\n",
    "\n",
    "# Readmission rate\n",
    "if 'Admissions' in df:\n",
    "    readm_rate = df['Admissions']['ReadmissionFlag'].mean()*100\n",
    "    print(f'Readmission rate: {readm_rate:.2f}%')\n",
    "\n",
    "# ER wait time\n",
    "if 'ResourceUtilizationSnapshots' in df:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.boxplot(df['ResourceUtilizationSnapshots']['ERWaitTimeMinutes'].dropna())\n",
    "    plt.title('ER Wait Time (minutes) - Distribution')\n",
    "    plt.ylabel('Minutes')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'er_wait_box.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64868302",
   "metadata": {},
   "source": [
    "## 6. Staff Efficiency\n",
    "Analyze staff utilization and salary vs experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df77b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Staff' in df:\n",
    "    staff_summary = df['Staff'].groupby('Role').agg(Count=('StaffID','count'), AvgExp=('ExperienceYears','mean'), AvgSalary=('Salary','mean')).reset_index()\n",
    "    display(staff_summary)\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.barplot(data=staff_summary, x='Role', y='AvgSalary')\n",
    "    plt.title('Avg Salary by Role')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'avg_salary_role.png'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.boxplot(data=df['Staff'], x='Role', y='ExperienceYears')\n",
    "    plt.title('Experience Years by Role')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'exp_box_role.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6d61c2",
   "metadata": {},
   "source": [
    "## 7. Patient & Admission Insights\n",
    "Age, gender, admission types, and outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76cdf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Patients' in df:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(df['Patients']['Age'].dropna(), bins=30)\n",
    "    plt.title('Patient Age Distribution')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'age_dist.png'))\n",
    "    plt.show()\n",
    "\n",
    "if 'Admissions' in df:\n",
    "    adm_by_type = df['Admissions']['AdmissionType'].value_counts(normalize=True)*100\n",
    "    print('Admission types (%):')\n",
    "    display(adm_by_type)\n",
    "\n",
    "    outcome_los = df['Admissions'].groupby('Outcome')['LengthOfStay'].mean().reset_index()\n",
    "    display(outcome_los)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.barplot(data=outcome_los, x='Outcome', y='LengthOfStay')\n",
    "    plt.title('Avg LOS by Outcome')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'los_by_outcome.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62371c8f",
   "metadata": {},
   "source": [
    "## 8. Surgery Outcomes & Efficiency\n",
    "Analyze surgery durations, complication rates, and surgeon workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eaffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Surgeries' in df:\n",
    "    print('Surgeries summary:')\n",
    "    display(df['Surgeries'].describe(include='all'))\n",
    "\n",
    "    surg_by_type = df['Surgeries'].groupby('SurgeryType').agg(Count=('SurgeryID','count'), AvgDuration=('DurationMinutes','mean'), CompRate=('ComplicationFlag','mean')).reset_index()\n",
    "    display(surg_by_type.sort_values('Count', ascending=False).head(10))\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(data=surg_by_type.sort_values('AvgDuration', ascending=False).head(10), x='AvgDuration', y='SurgeryType')\n",
    "    plt.title('Top 10 Surgery Types by Avg Duration')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'surg_top10_avgdur.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c716e7",
   "metadata": {},
   "source": [
    "## 9. Resource Utilization Trends (time-series)\n",
    "Aggregate snapshots by month and visualize trends for occupancy and ER wait time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f62870",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ResourceUtilizationSnapshots' in df:\n",
    "    snaps = df['ResourceUtilizationSnapshots'].copy()\n",
    "    snaps['SnapshotDate'] = pd.to_datetime(snaps['SnapshotDate'])\n",
    "    snaps['Month'] = snaps['SnapshotDate'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "    monthly = snaps.groupby('Month').agg(AvgBedOcc=('BedOccupancyRate','mean'), AvgERWait=('ERWaitTimeMinutes','mean')).reset_index()\n",
    "    display(monthly.head())\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(monthly['Month'], monthly['AvgBedOcc']*100, marker='o')\n",
    "    plt.title('Monthly Avg Bed Occupancy (%)')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Occupancy %')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'monthly_bedocc.png'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(monthly['Month'], monthly['AvgERWait'], marker='o', color='orange')\n",
    "    plt.title('Monthly Avg ER Wait (min)')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Minutes')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'monthly_erwait.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20222b0b",
   "metadata": {},
   "source": [
    "## 10. Financial Snapshot & Profitability\n",
    "Analyze profit margins and insurance coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Financials' in df:\n",
    "    fin = df['Financials'].copy()\n",
    "    fin['MonthStart'] = pd.to_datetime(fin['MonthStart'])\n",
    "    profit_by_dept = fin.groupby('DeptID').agg(AvgProfitMargin=('ProfitMargin','mean'), AvgInsuranceCov=('InsuranceCoveragePct','mean')).reset_index()\n",
    "    display(profit_by_dept.sort_values('AvgProfitMargin', ascending=False).head(10))\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(fin['ProfitMargin'].dropna(), bins=50)\n",
    "    plt.title('Profit Margin Distribution')\n",
    "    plt.xlabel('Profit Margin')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'profit_margin_hist.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30424baa",
   "metadata": {},
   "source": [
    "## 11. Correlation & Feature Relationships\n",
    "Compute correlations for numeric operational features and plot a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3632619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a numeric features frame\n",
    "num_frames = []\n",
    "if 'Admissions' in df:\n",
    "    num_frames.append(df['Admissions'][['LengthOfStay','ReadmissionFlag']])\n",
    "if 'ResourceUtilizationSnapshots' in df:\n",
    "    snaps = df['ResourceUtilizationSnapshots'][['BedOccupancyRate','EquipmentUtilizationRate','StaffUtilizationRate','ERWaitTimeMinutes']]\n",
    "    num_frames.append(snaps)\n",
    "\n",
    "if num_frames:\n",
    "    num_df = pd.concat(num_frames, axis=1)\n",
    "    num_df = num_df.select_dtypes(include=[np.number]).dropna()\n",
    "    corr = num_df.corr()\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap (numeric features)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,'corr_heatmap.png'))\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No numeric frames available for correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d95df3",
   "metadata": {},
   "source": [
    "## 12. Export aggregated CSVs for Power BI\n",
    "Export light-weight aggregates that Power BI will use for dashboards (e.g., monthly occupancy, top high-LOS patients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example exports\n",
    "if 'Admissions' in df:\n",
    "    monthly_adm = df['Admissions'].copy()\n",
    "    monthly_adm['AdmissionDate'] = pd.to_datetime(monthly_adm['AdmissionDate'])\n",
    "    monthly_adm['Month'] = monthly_adm['AdmissionDate'].dt.to_period('M').dt.to_timestamp()\n",
    "    agg_month = monthly_adm.groupby('Month').agg(TotalAdmissions=('AdmissionID','count'), AvgLOS=('LengthOfStay','mean')).reset_index()\n",
    "    agg_month.to_csv(os.path.join(OUTPUT_DIR,'agg_monthly_admissions.csv'), index=False)\n",
    "    print('Saved agg_monthly_admissions.csv')\n",
    "\n",
    "if 'ResourceUtilizationSnapshots' in df:\n",
    "    snaps = df['ResourceUtilizationSnapshots'].copy()\n",
    "    snaps.to_csv(os.path.join(OUTPUT_DIR,'resource_snapshots_export.csv'), index=False)\n",
    "    print('Saved resource_snapshots_export.csv')\n",
    "\n",
    "if 'Admissions' in df:\n",
    "    top_los = df['Admissions'].sort_values('LengthOfStay', ascending=False).head(100)\n",
    "    top_los.to_csv(os.path.join(OUTPUT_DIR,'top100_los.csv'), index=False)\n",
    "    print('Saved top100_los.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c923c5cd",
   "metadata": {},
   "source": [
    "## 13. Key Takeaways & Next Steps\n",
    "- Summarize findings and propose next steps (predictive modeling for discharge delay, staff scheduling optimization, and Power BI dashboards)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
